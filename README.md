# Speech-Emotion-Recognition
This focuses on identifying human emotions and states through speech.
# Data description
The data used here is the RAVDESS dataset; this is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset and is free to download.
# Model description
We have used two models for this project.
Model 1
MLPClassifier-- Multi-layer perceptron classifier model is a feedforward ANN model that maps input data sets to a set of appropriate outputs.
Model 2
CNN -- Convolutional Neutral Network Model.CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation using multiple building blocks, such as convolution, pooling, and fully connected layers.
Traditionally 2D CNN (Conv2D) is used but here we use 1D CNN (Conv1D) for our project.
We have built this model using TensorFlow Keras.
